<!DOCTYPE html><html lang="en"> <head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><!-- Favicons based on https://evilmartians.com/chronicles/how-to-favicon-in-2021-six-files-that-fit-most-needs --><link rel="icon" href="/favicon.ico" sizes="32x32"><link rel="icon" href="/favicon.svg" type="image/svg+xml"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="manifest" href="/manifest.webmanifest"><!-- Primary Meta Tags --><title>How to Set Up an LLM Server with Debian and Ollama | Borja LoFe</title><meta name="title" content="How to Set Up an LLM Server with Debian and Ollama | Borja LoFe"><meta name="description" content="A step-by-step guide to installing and configuring a large language model (LLM) server using Debian and Ollama."><!-- Canonical URL --><link rel="canonical" href="https://borjalofe/blog/how-to-set-up-a-llms-server-with-debian-and-ollama/"><link rel="alternate" hreflang="es" href="https://borjalofe/es/blog/como-montar-un-servidor-de-llms-con-debian-y-ollama"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://borjalofe/blog/how-to-set-up-a-llms-server-with-debian-and-ollama/"><meta property="og:title" content="How to Set Up an LLM Server with Debian and Ollama | Borja LoFe"><meta property="og:description" content="A step-by-step guide to installing and configuring a large language model (LLM) server using Debian and Ollama."><meta property="og:image" content="https://borjalofe/blog-placeholder-6.jpg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://borjalofe/blog/how-to-set-up-a-llms-server-with-debian-and-ollama/"><meta property="twitter:title" content="How to Set Up an LLM Server with Debian and Ollama | Borja LoFe"><meta property="twitter:description" content="A step-by-step guide to installing and configuring a large language model (LLM) server using Debian and Ollama."><meta property="twitter:image" content="https://borjalofe/blog-placeholder-6.jpg"><!-- Font preloads --><link rel="preload" href="/fonts/atkinson-regular.woff" as="font" type="font/woff" crossorigin><link rel="preload" href="/fonts/atkinson-bold.woff" as="font" type="font/woff" crossorigin><style>:root{--accent: #2337ff;--accent-dark: #000d8a;--black: 15, 18, 25;--gray: 96, 115, 159;--gray-light: 229, 233, 240;--gray-dark: 34, 41, 57;--gray-gradient: rgba(var(--gray-light), 50%), #fff;--box-shadow: 0 2px 6px rgba(var(--gray), 25%), 0 8px 24px rgba(var(--gray), 33%), 0 16px 32px rgba(var(--gray), 33%)}@font-face{font-family:Atkinson;src:url(/fonts/atkinson-regular.woff) format("woff");font-weight:400;font-style:normal;font-display:swap}@font-face{font-family:Atkinson;src:url(/fonts/atkinson-bold.woff) format("woff");font-weight:700;font-style:normal;font-display:swap}body{font-family:Atkinson,sans-serif;margin:0;padding:0;text-align:left;background:linear-gradient(var(--gray-gradient)) no-repeat;background-size:100% 600px;word-wrap:break-word;overflow-wrap:break-word;color:rgb(var(--gray-dark));font-size:20px;line-height:1.7}main{width:960px;max-width:calc(100% - 2em);margin:auto;padding:3em 1em}h1,h2,h3,h4,h5,h6{margin:0 0 .5rem;color:rgb(var(--black));line-height:1.2}h1{font-size:3.052em}h2{font-size:2.441em}h3{font-size:1.953em}h4{font-size:1.563em}h5{font-size:1.25em}strong,b{font-weight:700}a,a:hover{color:var(--accent)}p{margin-bottom:1em}.prose p{margin-bottom:2em}textarea{width:100%;font-size:16px}input{font-size:16px}table{width:100%}img{max-width:100%;height:auto;border-radius:8px}code{padding:2px 5px;background-color:rgb(var(--gray-light));border-radius:2px}pre{padding:1.5em;border-radius:8px}pre>code{all:unset}blockquote{border-left:4px solid var(--accent);padding:0 0 0 20px;margin:0;font-size:1.333em}hr{border:none;border-top:1px solid rgb(var(--gray-light))}@media (max-width: 720px){body{font-size:18px}main{padding:1em}}.sr-only{border:0;padding:0;margin:0;position:absolute!important;height:1px;width:1px;overflow:hidden;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);clip-path:inset(50%);white-space:nowrap}a[data-astro-cid-eimmu3lg]{display:inline-block;text-decoration:none}a[data-astro-cid-eimmu3lg].active{font-weight:bolder;text-decoration:underline}header[data-astro-cid-3ef6ksr2]{margin:0;padding:0 1em;background:#fff;box-shadow:0 2px 8px rgba(var(--black),5%)}h2[data-astro-cid-3ef6ksr2]{margin:0;font-size:1em}h2[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2],h2[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2].active{text-decoration:none}nav[data-astro-cid-3ef6ksr2]{display:flex;align-items:center;justify-content:space-between}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{padding:1em .5em;color:var(--black);border-bottom:4px solid transparent;text-decoration:none}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2].active{text-decoration:none;border-bottom-color:var(--accent)}.social-links[data-astro-cid-3ef6ksr2],.social-links[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{display:flex}@media (max-width: 720px){.social-links[data-astro-cid-3ef6ksr2]{display:none}}footer[data-astro-cid-sz7xmlte]{padding:2em 1em 6em;background:linear-gradient(var(--gray-gradient)) no-repeat;color:rgb(var(--gray));text-align:center}.social-links[data-astro-cid-sz7xmlte]{display:flex;justify-content:center;gap:1em;margin-top:1em}.social-links[data-astro-cid-sz7xmlte] a[data-astro-cid-sz7xmlte]{text-decoration:none;color:rgb(var(--gray))}.social-links[data-astro-cid-sz7xmlte] a[data-astro-cid-sz7xmlte]:hover{color:rgb(var(--gray-dark))}.skip-link-wrapper[data-astro-cid-hoe5mouk]{display:flex;justify-content:center;position:absolute;top:-100vh;left:auto;right:auto;width:100%;opacity:0;pointer-events:none;transform:translateY(0);transition:top var(--duration-link) linear var(--duration-link),opacity var(--duration-link) ease-in,transform var(--duration-link) ease-in}.skip-link-wrapper[data-astro-cid-hoe5mouk]:focus-within{top:0;opacity:1;transform:translateY(var(--space-m));transition:opacity var(--duration-link-hover) ease-out,transform var(--duration-link-hover) ease-out}.skip-link[data-astro-cid-hoe5mouk]{padding:var(--space-xs);background-color:var(--bg-light);pointer-events:all}
.menu-container[data-astro-cid-7xjzxsz4]{position:relative;display:inline-block}.menu-checkbox[data-astro-cid-7xjzxsz4]{display:none}.menu-label[data-astro-cid-7xjzxsz4]{cursor:pointer;padding:10px 20px;border:none;border-radius:4px;display:inline-block}.menu-content[data-astro-cid-7xjzxsz4]{display:none;position:absolute;background-color:#f9f9f9;min-width:70px;box-shadow:0 8px 16px #0003;z-index:1;margin-top:5px;border-radius:4px}.menu-content[data-astro-cid-7xjzxsz4] a[data-astro-cid-7xjzxsz4]{color:#000;padding:12px 16px;text-decoration:none;display:block}.menu-content[data-astro-cid-7xjzxsz4] a[data-astro-cid-7xjzxsz4]:hover{background-color:#f1f1f1}.menu-checkbox[data-astro-cid-7xjzxsz4]:checked+.menu-label[data-astro-cid-7xjzxsz4]+.menu-content[data-astro-cid-7xjzxsz4]{display:block}.caret-icon[data-astro-cid-7xjzxsz4]{transition:transform .3s ease}.menu-checkbox[data-astro-cid-7xjzxsz4]:checked+.menu-label[data-astro-cid-7xjzxsz4] .caret-icon[data-astro-cid-7xjzxsz4]{transform:rotate(-180deg)}
ul[data-astro-cid-wfyxae4o]{display:flex;flex-wrap:wrap;gap:2rem;list-style-type:none;margin:0;padding:0}ul[data-astro-cid-wfyxae4o] li[data-astro-cid-wfyxae4o]{width:calc(50% - 1rem)}ul[data-astro-cid-wfyxae4o] li[data-astro-cid-wfyxae4o] [data-astro-cid-wfyxae4o]{text-decoration:none;transition:.2s ease}ul[data-astro-cid-wfyxae4o] li[data-astro-cid-wfyxae4o]:first-child{width:100%;margin-bottom:1rem;text-align:center}ul[data-astro-cid-wfyxae4o] li[data-astro-cid-wfyxae4o]:first-child img[data-astro-cid-wfyxae4o]{width:100%}ul[data-astro-cid-wfyxae4o] li[data-astro-cid-wfyxae4o]:first-child .title[data-astro-cid-wfyxae4o]{font-size:2.369rem}ul[data-astro-cid-wfyxae4o] li[data-astro-cid-wfyxae4o] img[data-astro-cid-wfyxae4o]{margin-bottom:.5rem;border-radius:12px}ul[data-astro-cid-wfyxae4o] li[data-astro-cid-wfyxae4o] a[data-astro-cid-wfyxae4o]{display:block}.title[data-astro-cid-wfyxae4o]{margin:0;color:rgb(var(--black));line-height:1}.date[data-astro-cid-wfyxae4o]{margin:0;color:rgb(var(--gray))}ul[data-astro-cid-wfyxae4o] li[data-astro-cid-wfyxae4o] a[data-astro-cid-wfyxae4o]:hover h4[data-astro-cid-wfyxae4o],ul[data-astro-cid-wfyxae4o] li[data-astro-cid-wfyxae4o] a[data-astro-cid-wfyxae4o]:hover .date[data-astro-cid-wfyxae4o]{color:rgb(var(--accent))}ul[data-astro-cid-wfyxae4o] a[data-astro-cid-wfyxae4o]:hover img[data-astro-cid-wfyxae4o]{box-shadow:var(--box-shadow)}@media (max-width: 720px){ul[data-astro-cid-wfyxae4o]{gap:.5em}ul[data-astro-cid-wfyxae4o] li[data-astro-cid-wfyxae4o]{width:100%;text-align:center}ul[data-astro-cid-wfyxae4o] li[data-astro-cid-wfyxae4o]:first-child{margin-bottom:0}ul[data-astro-cid-wfyxae4o] li[data-astro-cid-wfyxae4o]:first-child .title[data-astro-cid-wfyxae4o]{font-size:1.563em}}
</style><script type="module">(function(){const t=document.querySelector("#main>article")?.getAttribute("data-locales")?.split(","),o=document.querySelector("#main>article")?.getAttribute("data-selected-locale");if(t&&t?.length>0){let l=[];for(const e of t)l=[...l,...Array.from(document.querySelectorAll(`#main [lang="${e}"]`))];for(const e of l)e.getAttribute("lang")!==o?e.remove():(e.tagName.toLowerCase()==="h1"&&(document.title=e.innerHTML),e.style.display="block")}})();
</script></head><body> <header data-astro-cid-3ef6ksr2> <nav data-astro-cid-3ef6ksr2> <h2 data-astro-cid-3ef6ksr2><a href="/" data-astro-cid-3ef6ksr2>Borja LoFe</a></h2> <div class="internal-links" data-astro-cid-3ef6ksr2> <a href="/" data-astro-cid-3ef6ksr2 data-astro-cid-eimmu3lg> Home </a> <a href="/blog" data-astro-cid-3ef6ksr2 data-astro-cid-eimmu3lg> Blog </a>  </div>  <div class="menu-container" data-astro-cid-7xjzxsz4>  <input type="checkbox" id="menu-toggle" class="menu-checkbox" data-astro-cid-7xjzxsz4> <label for="menu-toggle" class="menu-label" data-astro-cid-7xjzxsz4> EN <svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="caret-icon" data-astro-cid-7xjzxsz4> <polyline points="6 9 12 15 18 9" data-astro-cid-7xjzxsz4></polyline> </svg> </label> <div class="menu-content" data-astro-cid-7xjzxsz4> <a href="/es/blog/como-montar-un-servidor-de-llms-con-debian-y-ollama" data-astro-cid-7xjzxsz4>ES</a> </div>  </div>   <div class="social-links" data-astro-cid-3ef6ksr2> <a href="https://twitter.com/borjalofe" target="_blank" data-astro-cid-3ef6ksr2> <span class="sr-only" data-astro-cid-3ef6ksr2>Sígueme en Twitter</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" data-astro-cid-3ef6ksr2><path fill="currentColor" d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334 0-.14 0-.282-.006-.422A6.685 6.685 0 0 0 16 3.542a6.658 6.658 0 0 1-1.889.518 3.301 3.301 0 0 0 1.447-1.817 6.533 6.533 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.325 9.325 0 0 1-6.767-3.429 3.289 3.289 0 0 0 1.018 4.382A3.323 3.323 0 0 1 .64 6.575v.045a3.288 3.288 0 0 0 2.632 3.218 3.203 3.203 0 0 1-.865.115 3.23 3.23 0 0 1-.614-.057 3.283 3.283 0 0 0 3.067 2.277A6.588 6.588 0 0 1 .78 13.58a6.32 6.32 0 0 1-.78-.045A9.344 9.344 0 0 0 5.026 15z" data-astro-cid-3ef6ksr2></path></svg> </a> <a href="https://github.com/borjalofe" target="_blank" data-astro-cid-3ef6ksr2> <span class="sr-only" data-astro-cid-3ef6ksr2>Mi repo en GitHub</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" data-astro-cid-3ef6ksr2><path fill="currentColor" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" data-astro-cid-3ef6ksr2></path></svg> </a> </div> </nav> </header>  <div class="skip-link-wrapper" data-astro-cid-hoe5mouk> <a href="#main" class="skip-link" tabindex="-1" data-astro-cid-hoe5mouk>Skip to content</a> </div>   <main id="main">  <article><div class="hero-image"><img src="/blog-placeholder-6.jpg" alt="" loading="eager" width="720" height="360" decoding="async"></div><div class="prose"><div class="title"><div class="date"><time datetime="2024-10-21T09:00:00.000Z"> Oct 21, 2024 </time></div><h1>How to Set Up an LLM Server with Debian and Ollama</h1><hr></div> <p>In a previous article, we set up an old laptop with Debian as a server for remote access. Now it’s time to set up a large language model (LLM) server using Debian and Ollama, and configure Docker to manage everything efficiently.</p>
<h2 id="1-installing-docker">1. Installing Docker</h2>
<p>Docker allows the use of containers and efficient application management by isolating these applications.</p>
<p>Therefore, we are going to install it to manage the web interface we will use.</p>
<p>First, install the dependencies with:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#50FA7B">sudo</span><span style="color:#F1FA8C"> apt</span><span style="color:#BD93F9"> -qy</span><span style="color:#F1FA8C"> install</span><span style="color:#F1FA8C"> software-properties-common</span><span style="color:#F1FA8C"> apt-transport-https</span><span style="color:#F1FA8C"> ca-certificates</span><span style="color:#F1FA8C"> curl</span><span style="color:#F1FA8C"> gnupg</span><span style="color:#F1FA8C"> lsb-release</span></span>
<span class="line"></span></code></pre>
<p>Next, add the Docker GPG key with:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#50FA7B">sudo</span><span style="color:#F1FA8C"> mkdir</span><span style="color:#BD93F9"> -p</span><span style="color:#F1FA8C"> /etc/apt/keyrings</span></span>
<span class="line"><span style="color:#50FA7B">curl</span><span style="color:#BD93F9"> -fsSL</span><span style="color:#F1FA8C"> https://download.docker.com/linux/debian/gpg</span><span style="color:#FF79C6"> |</span><span style="color:#50FA7B"> sudo</span><span style="color:#F1FA8C"> gpg</span><span style="color:#BD93F9"> --dearmor</span><span style="color:#BD93F9"> -o</span><span style="color:#F1FA8C"> /etc/apt/keyrings/docker.gpg</span></span>
<span class="line"></span></code></pre>
<p>Then, configure the Docker repositories so that apt (Debian’s package manager) knows where to install it from:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#8BE9FD">echo</span><span style="color:#E9F284"> "</span><span style="color:#F1FA8C">deb [arch=$(</span><span style="color:#50FA7B">dpkg</span><span style="color:#BD93F9"> --print-architecture</span><span style="color:#F1FA8C">) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian $(</span><span style="color:#50FA7B">lsb_release</span><span style="color:#BD93F9"> -cs</span><span style="color:#F1FA8C">) stable</span><span style="color:#E9F284">"</span><span style="color:#FF79C6"> |</span><span style="color:#50FA7B"> sudo</span><span style="color:#F1FA8C"> tee</span><span style="color:#F1FA8C"> /etc/apt/sources.list.d/docker.list</span><span style="color:#FF79C6"> ></span><span style="color:#F1FA8C"> /dev/null</span></span>
<span class="line"></span></code></pre>
<p>Once this is done, simply update the repository information with:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#50FA7B">sudo</span><span style="color:#F1FA8C"> apt</span><span style="color:#BD93F9"> -qy</span><span style="color:#F1FA8C"> update</span></span>
<span class="line"></span></code></pre>
<p>And install Docker with:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#50FA7B">sudo</span><span style="color:#F1FA8C"> apt</span><span style="color:#BD93F9"> -qy</span><span style="color:#F1FA8C"> install</span><span style="color:#F1FA8C"> docker-ce</span><span style="color:#F1FA8C"> docker-ce-cli</span><span style="color:#F1FA8C"> containerd.io</span><span style="color:#F1FA8C"> docker-compose-plugin</span></span>
<span class="line"></span></code></pre>
<p>To gain some security, we will allow the use of Docker without superuser privileges (known as rootless usage), for which we will add our user to the Docker users group with:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#50FA7B">sudo</span><span style="color:#F1FA8C"> usermod</span><span style="color:#BD93F9"> -aG</span><span style="color:#F1FA8C"> docker</span><span style="color:#BD93F9"> $USER</span></span>
<span class="line"></span></code></pre>
<p>We do not need to replace anything because the system already has our user in the $USER variable from the login.</p>
<h2 id="2-installing-ollama">2. Installing Ollama</h2>
<p>Ollama is the tool we will use to manage the LLMs on our server. The installation is straightforward and is done with a single command:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#50FA7B">curl</span><span style="color:#BD93F9"> -fsSL</span><span style="color:#F1FA8C"> https://ollama.com/install.sh</span><span style="color:#FF79C6"> |</span><span style="color:#50FA7B"> sh</span></span>
<span class="line"></span></code></pre>
<p>This will download and install Ollama, making it ready to manage the models on our server.</p>
<p>I know there is a Docker-based installation, but I haven’t had the chance to look into it yet. However, I will update this article in the future to add that alternative.</p>
<h2 id="3-enabling-connections-from-the-local-network">3. Enabling Connections from the Local Network</h2>
<p>To access Ollama from other devices on the local network, we need to modify its configuration to accept external connections.</p>
<p>First, make a backup!</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#50FA7B">sudo</span><span style="color:#F1FA8C"> cp</span><span style="color:#F1FA8C"> /etc/systemd/system/ollama.serve</span><span style="color:#F1FA8C"> /etc/systemd/system/ollama.serve.bak</span></span>
<span class="line"></span></code></pre>
<p>Then open it with <code>nano</code>:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#50FA7B">sudo</span><span style="color:#F1FA8C"> nano</span><span style="color:#F1FA8C"> /etc/systemd/system/ollama.serve</span></span>
<span class="line"></span></code></pre>
<p>Find the line that says <code>[Service]</code> and just below it, add the following lines:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#BD93F9">Environment</span><span style="color:#FF79C6">=</span><span style="color:#E9F284">"</span><span style="color:#F1FA8C">OLLAMA_HOST=0.0.0.0</span><span style="color:#E9F284">"</span></span>
<span class="line"><span style="color:#BD93F9">Environment</span><span style="color:#FF79C6">=</span><span style="color:#E9F284">"</span><span style="color:#F1FA8C">OLLAMA_ORIGINS=*</span><span style="color:#E9F284">"</span></span>
<span class="line"></span></code></pre>
<p>These lines might already exist, either commented out or with different values. The important thing is that the file includes the lines as I have provided.</p>
<p>With this, Ollama will accept connections from any origin, facilitating remote access to the models from any device on the local network.</p>
<h2 id="4-installing-open-web-ui">4. Installing Open Web UI</h2>
<p>Open Web UI is the graphical administration interface that makes it easier to interact with Ollama from any browser. Install the web interface using Docker:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#50FA7B">sudo</span><span style="color:#F1FA8C"> docker</span><span style="color:#F1FA8C"> run</span><span style="color:#BD93F9"> -d</span><span style="color:#BD93F9"> -p</span><span style="color:#F1FA8C"> 3000:8080</span><span style="color:#BD93F9"> -e</span><span style="color:#F1FA8C"> OLLAMA_BASE_URL=http://</span><span style="color:#F8F8F2">$(</span><span style="color:#50FA7B">hostname</span><span style="color:#BD93F9"> -I</span><span style="color:#FF79C6"> |</span><span style="color:#50FA7B"> awk</span><span style="color:#E9F284"> '</span><span style="color:#F1FA8C">{print $1}</span><span style="color:#E9F284">'</span><span style="color:#F8F8F2">)</span><span style="color:#F1FA8C">:11434</span><span style="color:#BD93F9"> -v</span><span style="color:#F1FA8C"> open-webui:/app/backend/data</span><span style="color:#BD93F9"> --name</span><span style="color:#F1FA8C"> open-webui</span><span style="color:#BD93F9"> --restart</span><span style="color:#F1FA8C"> always</span><span style="color:#F1FA8C"> ghcr.io/open-webui/open-webui:main</span></span>
<span class="line"></span></code></pre>
<p>This command takes care of everything necessary:</p>
<ul>
<li>Configuring the interface to start automatically,</li>
<li>Pointing to the address and port where Ollama is listening,</li>
<li>And setting up a port where it will listen for requests.</li>
</ul>
<p>With this, you can access the web interface from <code>http://192.168.1.100:3000</code> (or the IP you configured as the fixed IP of your server).</p>
<h2 id="5-installing-llms">5. Installing LLMs</h2>
<p>Everything is ready to install the models… so let’s install one!</p>
<p>All we need to do is execute the following command:</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#50FA7B">ollama</span><span style="color:#F1FA8C"> pull</span><span style="color:#FF79C6"> &#x3C;</span><span style="color:#F1FA8C">mode</span><span style="color:#F8F8F2">l</span><span style="color:#FF79C6">></span></span>
<span class="line"></span></code></pre>
<p>You can see which models are available for Ollama on their <a href="https://ollama.com/library">website</a>.</p>
<p>You will need to replace <code>&#x3C;model></code> with the LLM you want to install, and that’s it.</p>
<h2 id="problems-i-have-encountered">Problems I Have Encountered</h2>
<p>During the configuration and use of Ollama, I encountered some problems. Below, I discuss the issues I faced and how I resolved them.</p>
<h3 id="error-no-suitable-llama-server-found">Error: <code>no suitable llama server found</code></h3>
<p>This error usually indicates that the model could not be loaded. In general, models are loaded into the <code>/tmp</code> folder, so the first thing I did was check that there was enough space in that folder and, by increasing the space (or deleting some files on the disk), the problem disappeared.</p>
<h2 id="conclusion">Conclusion</h2>
<p>With these steps, we have set up a large language model (LLM) server using Debian, Ollama, and Docker. Now, any device on your local network can access the installed models through the web interface, making this environment ideal for testing and experimentation.</p>
<p>It also helps bring these technologies closer to all family members with complete security.</p>
<p>I hope you enjoy exploring the potential of LLMs on your own server!</p> </div></article><style>
			.hero-image {
				width: 100%;
			}
			.hero-image img {
				display: block;
				margin: 0 auto;
				border-radius: 12px;
				box-shadow: var(--box-shadow);
			}
			.prose {
				width: 720px;
				max-width: calc(100% - 2em);
				margin: auto;
				padding: 1em;
				color: rgb(var(--gray-dark));
			}
			.title {
				margin-bottom: 1em;
				padding: 1em 0;
				text-align: center;
				line-height: 1;
			}
			.title h1 {
				margin: 0 0 0.5em 0;
			}
			.date {
				margin-bottom: 0.5em;
				color: rgb(var(--gray));
			}
			.last-updated-on {
				font-style: italic;
			}
		</style>  </main>  <footer data-astro-cid-sz7xmlte>   
&copy; 2025 Borja LoFe.
<div class="social-links" data-astro-cid-sz7xmlte> <a href="https://twitter.com/borjalofe" target="_blank" data-astro-cid-sz7xmlte> <span class="sr-only" data-astro-cid-sz7xmlte>Sígueme en Twitter</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" data-astro-cid-sz7xmlte><path fill="currentColor" d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334 0-.14 0-.282-.006-.422A6.685 6.685 0 0 0 16 3.542a6.658 6.658 0 0 1-1.889.518 3.301 3.301 0 0 0 1.447-1.817 6.533 6.533 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.325 9.325 0 0 1-6.767-3.429 3.289 3.289 0 0 0 1.018 4.382A3.323 3.323 0 0 1 .64 6.575v.045a3.288 3.288 0 0 0 2.632 3.218 3.203 3.203 0 0 1-.865.115 3.23 3.23 0 0 1-.614-.057 3.283 3.283 0 0 0 3.067 2.277A6.588 6.588 0 0 1 .78 13.58a6.32 6.32 0 0 1-.78-.045A9.344 9.344 0 0 0 5.026 15z" data-astro-cid-sz7xmlte></path></svg> </a> <a href="https://github.com/borjalofe" target="_blank" data-astro-cid-sz7xmlte> <span class="sr-only" data-astro-cid-sz7xmlte>Mi repo en GitHub</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" data-astro-cid-sz7xmlte><path fill="currentColor" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" data-astro-cid-sz7xmlte></path></svg> </a> </div> </footer>  </body></html>